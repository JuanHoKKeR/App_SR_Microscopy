"""
Visualizador de resultados corregido
Muestra im√°genes en tama√±os proporcionales y m√©tricas correctas
"""

import streamlit as st
import base64
import numpy as np
from PIL import Image
from typing import Dict, Any, List, Optional
import io
import logging

from .ui_config import show_info_box, show_metric_card

logger = logging.getLogger(__name__)

class ResultsViewer:
    """Visualizador de resultados corregido"""
    
    def __init__(self):
        pass
    
    def display_scale_results(self, result: Dict[str, Any]):
        """Muestra resultados de procesamiento por escala"""
        if not result or not result.get("success", False):
            st.error("‚ùå No hay resultados v√°lidos para mostrar")
            return
        
        st.markdown('<h2 class="sub-header">üéâ Resultados del Procesamiento</h2>', unsafe_allow_html=True)
        
        # Resumen del procesamiento
        self._show_processing_summary(result)
        
        # Comparaci√≥n con tama√±os proporcionales
        self._show_proportional_comparison(result)
        
        # M√©tricas de calidad
        self._show_quality_metrics_enhanced(result)
        
        # Progresi√≥n paso a paso
        self._show_step_progression(result)
        
        # Opciones de descarga
        self._show_download_options(result)
    
    def _show_processing_summary(self, result: Dict[str, Any]):
        """Muestra resumen del procesamiento realizado"""
        st.markdown("### üìä Resumen del Procesamiento")
        
        # Obtener informaci√≥n de configuraci√≥n
        config = result.get("config", {})
        selection = result.get("selection", {})
        
        # M√©tricas principales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            show_metric_card(
                config.get("architecture", result.get("architecture", "N/A")),
                "Arquitectura"
            )
        
        with col2:
            show_metric_card(
                f"√ó{config.get('target_scale', result.get('target_scale', 'N/A'))}",
                "Factor de Escala"
            )
        
        with col3:
            show_metric_card(
                f"{len(result.get('steps', []))}",
                "Pasos Aplicados"
            )
        
        with col4:
            original_size = result.get("original_size", "N/A")
            final_size = result.get("final_size", "N/A")
            show_metric_card(
                f"{original_size}‚Üí{final_size}",
                "Resoluci√≥n"
            )
        
        # Informaci√≥n detallada
        show_info_box(f"""
        **üõ§Ô∏è Ruta de procesamiento:** {' ‚Üí '.join(result.get('upsampling_path', []))}<br>
        **üìç Regi√≥n procesada:** ({selection.get('x', 0)}, {selection.get('y', 0)}) - {selection.get('width', 0)}√ó{selection.get('height', 0)} px<br>
        **üéØ Escalado conseguido:** {config.get('target_scale', result.get('target_scale', 'N/A'))}x
        """, "success")
    
    def _show_proportional_comparison(self, result: Dict[str, Any]):
        """Muestra comparaci√≥n con tama√±os proporcionales reales"""
        st.markdown("### üîç Comparaci√≥n con Tama√±os Proporcionales")
        
        original_b64 = result.get("original_patch")
        final_b64 = result.get("final_result")
        
        if not original_b64 or not final_b64:
            st.error("‚ùå Im√°genes de comparaci√≥n no disponibles")
            return
        
        # Convertir de base64 a im√°genes
        original_img = self._base64_to_image(original_b64)
        final_img = self._base64_to_image(final_b64)
        
        if original_img is None or final_img is None:
            st.error("‚ùå Error cargando im√°genes para comparaci√≥n")
            return
        
        # Obtener dimensiones reales
        config = result.get("config", {})
        target_scale = config.get("target_scale", result.get("target_scale", 2))
        
        # Layout de comparaci√≥n con tama√±os proporcionales
        col1, col2 = st.columns([1, target_scale])  # Columnas proporcionales al factor de escala
        
        with col1:
            st.markdown("#### üì∑ Imagen Original")
            st.image(original_img, caption=f"Original: {original_img.size[0]}√ó{original_img.size[1]} px")
            
            # Informaci√≥n adicional
            st.markdown(f"""
            **Tama√±o real:** {original_img.size[0]} √ó {original_img.size[1]} p√≠xeles  
            **√Årea:** {original_img.size[0] * original_img.size[1]:,} p√≠xeles¬≤
            """)
        
        with col2:
            st.markdown(f"#### üöÄ Resultado (√ó{target_scale})")
            st.image(final_img, caption=f"Procesado: {final_img.size[0]}√ó{final_img.size[1]} px")
            
            # Informaci√≥n adicional
            gain_factor = (final_img.size[0] * final_img.size[1]) / (original_img.size[0] * original_img.size[1])
            st.markdown(f"""
            **Tama√±o real:** {final_img.size[0]} √ó {final_img.size[1]} p√≠xeles  
            **√Årea:** {final_img.size[0] * final_img.size[1]:,} p√≠xeles¬≤  
            **Ganancia:** {gain_factor:.1f}√ó m√°s p√≠xeles
            """)
        
        # Mostrar diferencia visual de tama√±o
        st.markdown("#### üìè Comparaci√≥n Visual de Tama√±o")
        st.markdown("""
        üí° **Nota:** Las columnas est√°n dimensionadas proporcionalmente al factor de escala 
        para mostrar la diferencia real de tama√±o entre las im√°genes.
        """)
    
    def _show_quality_metrics_enhanced(self, result: Dict[str, Any]):
        """Muestra m√©tricas de calidad mejoradas"""
        quality_metrics = result.get("quality_metrics")
        
        if not quality_metrics:
            st.markdown("### üìà M√©tricas de Calidad")
            st.info("‚ÑπÔ∏è No se calcularon m√©tricas de calidad para este procesamiento")
            return
        
        if "error" in quality_metrics:
            show_info_box(f"""
            ‚ö†Ô∏è **Error en evaluaci√≥n de calidad:** {quality_metrics['error']}<br>
            Las m√©tricas de calidad no est√°n disponibles para este resultado.
            """, "warning")
            return
        
        st.markdown("### üìà M√©tricas de Calidad")
        
        # M√©tricas principales
        col1, col2, col3 = st.columns(3)
        
        metrics = quality_metrics.get("metrics") or quality_metrics
        interpretation = quality_metrics.get("interpretation", {})
        
        with col1:
            psnr_val = metrics.get("psnr", -1)
            if psnr_val > 0:
                # Determinar color basado en calidad
                if psnr_val > 30:
                    psnr_color = "üü¢"
                elif psnr_val > 25:
                    psnr_color = "üü°"
                else:
                    psnr_color = "üî¥"
                
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{psnr_color} {psnr_val:.2f} dB</div>
                    <div class="metric-label">PSNR - {interpretation.get('psnr', 'N/A')}</div>
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            ssim_val = metrics.get("ssim", -1)
            if ssim_val > 0:
                # Determinar color basado en calidad
                if ssim_val > 0.9:
                    ssim_color = "üü¢"
                elif ssim_val > 0.7:
                    ssim_color = "üü°"
                else:
                    ssim_color = "üî¥"
                
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{ssim_color} {ssim_val:.4f}</div>
                    <div class="metric-label">SSIM - {interpretation.get('ssim', 'N/A')}</div>
                </div>
                """, unsafe_allow_html=True)
        
        with col3:
            perceptual_val = metrics.get("perceptual_index", -1)
            if perceptual_val >= 0:
                # Determinar color basado en calidad (menor es mejor para perceptual)
                if perceptual_val < 0.001:
                    perc_color = "üü¢"
                elif perceptual_val < 0.01:
                    perc_color = "üü°"
                else:
                    perc_color = "üî¥"
                
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{perc_color} {perceptual_val:.6f}</div>
                    <div class="metric-label">√çndice Perceptual - {interpretation.get('perceptual', 'N/A')}</div>
                </div>
                """, unsafe_allow_html=True)
        
        # Informaci√≥n sobre KimiaNet
        kimianet_used = quality_metrics.get("kimianet_used", False)
        if kimianet_used:
            show_info_box("""
            üß† **KimiaNet Utilizado:** Las m√©tricas perceptuales se calcularon usando DenseNet121 
            con pesos KimiaNet, espec√≠ficamente entrenado para im√°genes de histopatolog√≠a de c√°ncer de mama.
            Esto proporciona una evaluaci√≥n m√°s relevante para tu dominio espec√≠fico.
            """, "success")
        else:
            show_info_box("""
            ‚ö†Ô∏è **KimiaNet No Disponible:** Las m√©tricas PSNR y SSIM est√°n disponibles, 
            pero el √≠ndice perceptual especializado no se pudo calcular.
            """, "warning")
        
        # Interpretaci√≥n detallada
        with st.expander("üìö Interpretaci√≥n de M√©tricas"):
            st.markdown("""
            **PSNR (Peak Signal-to-Noise Ratio):**
            - üü¢ > 30 dB: Excelente calidad, diferencias imperceptibles
            - üü° 25-30 dB: Buena calidad, diferencias m√≠nimas
            - üî¥ < 25 dB: Calidad aceptable pero con artefactos visibles
            
            **SSIM (Structural Similarity Index):**
            - üü¢ > 0.9: Excelente preservaci√≥n de estructura
            - üü° 0.7-0.9: Buena preservaci√≥n de estructura  
            - üî¥ < 0.7: P√©rdida notable de estructura
            
            **√çndice Perceptual (KimiaNet):**
            - üü¢ < 0.001: Excelente similitud perceptual
            - üü° 0.001-0.01: Buena similitud perceptual
            - üî¥ > 0.01: Diferencias perceptuales notables
            
            üí° **Para histopatolog√≠a de c√°ncer de mama**, el √≠ndice perceptual KimiaNet 
            es especialmente relevante ya que eval√∫a caracter√≠sticas espec√≠ficas del dominio.
            """)
    
    def _show_step_progression(self, result: Dict[str, Any]):
        """Muestra la progresi√≥n paso a paso del procesamiento"""
        st.markdown("### üîÑ Progresi√≥n Paso a Paso")
        
        steps = result.get("steps", [])
        if not steps:
            st.warning("No hay informaci√≥n de pasos disponible")
            return
        
        # Mostrar pasos en columnas si son pocos, tabs si son muchos
        if len(steps) <= 3:
            cols = st.columns(len(steps))
            for i, step in enumerate(steps):
                with cols[i]:
                    self._show_single_step(step, i + 1)
        else:
            # Usar tabs para muchos pasos
            tab_names = [f"Paso {step['step']}" for step in steps]
            tabs = st.tabs(tab_names)
            
            for tab, step in zip(tabs, steps):
                with tab:
                    self._show_single_step(step, step['step'], detailed=True)
    
    def _show_single_step(self, step: Dict[str, Any], step_number: int, detailed: bool = False):
        """Muestra un paso individual del procesamiento"""
        st.markdown(f"**Paso {step_number}: {step.get('model_name', 'Modelo desconocido')}**")
        
        # Mostrar imagen del paso
        if "enhanced_patch" in step:
            image_data = self._base64_to_image(step["enhanced_patch"])
            if image_data is not None:
                st.image(image_data, 
                        caption=f"Salida: {step.get('output_size', 'N/A')}",
                        use_column_width=True)
        
        if detailed:
            # Informaci√≥n adicional en modo detallado
            st.markdown(f"- **Entrada:** {step.get('input_size', 'N/A')}")
            st.markdown(f"- **Salida:** {step.get('output_size', 'N/A')}")
            
            # Informaci√≥n del modelo si est√° disponible
            model_config = step.get("model_config", {})
            if model_config:
                st.markdown(f"- **Tipo:** {model_config.get('type', 'N/A')}")
                if 'checkpoint_iter' in model_config:
                    st.markdown(f"- **Checkpoint:** {model_config['checkpoint_iter']}")
    
    def _show_download_options(self, result: Dict[str, Any]):
        """Muestra opciones de descarga"""
        st.markdown("### üíæ Opciones de Descarga")
        
        col1, col2, col3 = st.columns(3)
        
        config = result.get("config", {})
        
        with col1:
            # Descargar resultado final
            if "final_result" in result:
                final_bytes = self._base64_to_bytes(result["final_result"])
                if final_bytes:
                    st.download_button(
                        label="üì• Descargar Resultado Final",
                        data=final_bytes,
                        file_name=f"enhanced_x{config.get('target_scale', 'N')}_{config.get('architecture', 'unknown').lower()}.png",
                        mime="image/png",
                        type="primary"
                    )
        
        with col2:
            # Descargar imagen original del parche
            if "original_patch" in result:
                original_bytes = self._base64_to_bytes(result["original_patch"])
                if original_bytes:
                    st.download_button(
                        label="üì• Descargar Original",
                        data=original_bytes,
                        file_name="original_patch.png",
                        mime="image/png"
                    )
        
        with col3:
            # Generar reporte de m√©tricas
            if result.get("quality_metrics"):
                report_text = self._generate_metrics_report(result)
                st.download_button(
                    label="üìÑ Descargar Reporte",
                    data=report_text,
                    file_name="quality_report.txt",
                    mime="text/plain"
                )
    
    def _generate_metrics_report(self, result: Dict[str, Any]) -> str:
        """Genera reporte de texto con las m√©tricas"""
        config = result.get("config", {})
        metrics = result.get("quality_metrics", {}).get("metrics", {})
        
        report_lines = [
            "=== REPORTE DE SUPER-RESOLUCI√ìN ===",
            f"Fecha: {self._get_current_timestamp()}",
            "",
            "CONFIGURACI√ìN:",
            f"- Arquitectura: {config.get('architecture', 'N/A')}",
            f"- Factor de escala: √ó{config.get('target_scale', 'N/A')}",
            f"- Tama√±o de parche: {config.get('patch_size', 'N/A')}√ó{config.get('patch_size', 'N/A')} px",
            f"- Modelos utilizados: {len(result.get('upsampling_path', []))} pasos",
            "",
            "M√âTRICAS DE CALIDAD:",
            f"- PSNR: {metrics.get('psnr', 'N/A'):.4f} dB",
            f"- SSIM: {metrics.get('ssim', 'N/A'):.6f}",
            f"- √çndice Perceptual: {metrics.get('perceptual_index', 'N/A'):.8f}",
            "",
            "PROCESAMIENTO:",
            f"- Ruta: {' ‚Üí '.join(result.get('upsampling_path', []))}",
            f"- Resoluci√≥n inicial: {result.get('original_size', 'N/A')}",
            f"- Resoluci√≥n final: {result.get('final_size', 'N/A')}",
        ]
        
        return "\n".join(report_lines)
    
    def display_evaluation_results(self, result: Dict[str, Any], show_difference_map: bool = False):
        """Muestra resultados de evaluaci√≥n independiente"""
        st.markdown("### üìä Resultados de Evaluaci√≥n")
        
        if not result.get("success", False):
            st.error("‚ùå Error en la evaluaci√≥n")
            return
        
        # Mostrar m√©tricas principales
        metrics = result.get("metrics", {})
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            psnr = metrics.get("psnr", 0)
            show_metric_card(f"{psnr:.2f} dB", "PSNR")
        
        with col2:
            ssim = metrics.get("ssim", 0)
            show_metric_card(f"{ssim:.4f}", "SSIM")
        
        with col3:
            perceptual = metrics.get("perceptual_index", -1)
            if perceptual >= 0:
                show_metric_card(f"{perceptual:.6f}", "√çndice Perceptual")
            else:
                show_metric_card("N/A", "√çndice Perceptual")
        
        # Interpretaci√≥n
        interpretation = result.get("interpretation", {})
        if interpretation:
            st.markdown("**Interpretaci√≥n:**")
            for metric, interp in interpretation.items():
                st.markdown(f"- **{metric.upper()}:** {interp}")
    
    def _base64_to_image(self, base64_str: str) -> Optional[Image.Image]:
        """Convierte base64 a imagen PIL"""
        try:
            img_data = base64.b64decode(base64_str)
            image = Image.open(io.BytesIO(img_data))
            return image
        except Exception as e:
            logger.error(f"Error convirtiendo base64 a imagen: {e}")
            return None
    
    def _base64_to_bytes(self, base64_str: str) -> Optional[bytes]:
        """Convierte base64 a bytes"""
        try:
            return base64.b64decode(base64_str)
        except Exception as e:
            logger.error(f"Error convirtiendo base64 a bytes: {e}")
            return None
    
    def _get_current_timestamp(self) -> str:
        """Obtiene timestamp actual"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")